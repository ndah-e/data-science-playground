{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/aarshayj/Analytics_Vidhya/blob/master/Articles/Parameter_Tuning_XGBoost_with_Example/XGBoost%20models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pandas.core.algorithms as algos\n",
    "from pandas import Series\n",
    "import scipy.stats.stats as stats\n",
    "import re\n",
    "import traceback\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/CAX_MortgageModeling_Train.csv\")\n",
    "test = pd.read_csv(\"data/CAX_MortgageModeling_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45642, 22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>MORTGAGE NUMBER</th>\n",
       "      <th>PROPERTY VALUE</th>\n",
       "      <th>MORTGAGE PAYMENT</th>\n",
       "      <th>GDS</th>\n",
       "      <th>LTV</th>\n",
       "      <th>TDS</th>\n",
       "      <th>AMORTIZATION</th>\n",
       "      <th>MORTGAGE AMOUNT</th>\n",
       "      <th>RATE</th>\n",
       "      <th>...</th>\n",
       "      <th>PROPERTY TYPE</th>\n",
       "      <th>TERM</th>\n",
       "      <th>FSA</th>\n",
       "      <th>AGE RANGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>INCOME TYPE</th>\n",
       "      <th>NAICS CODE</th>\n",
       "      <th>CREDIT SCORE</th>\n",
       "      <th>RESULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CAX_Train_1</td>\n",
       "      <td>1</td>\n",
       "      <td>900000</td>\n",
       "      <td>5429</td>\n",
       "      <td>61.98</td>\n",
       "      <td>65.00</td>\n",
       "      <td>71.63</td>\n",
       "      <td>360</td>\n",
       "      <td>1040000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Single Detached</td>\n",
       "      <td>12</td>\n",
       "      <td>L4C</td>\n",
       "      <td>Under 25</td>\n",
       "      <td>Male</td>\n",
       "      <td>108000</td>\n",
       "      <td>8</td>\n",
       "      <td>44-45</td>\n",
       "      <td>681</td>\n",
       "      <td>FUNDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CAX_Train_2</td>\n",
       "      <td>2</td>\n",
       "      <td>386000</td>\n",
       "      <td>2179</td>\n",
       "      <td>35.22</td>\n",
       "      <td>74.29</td>\n",
       "      <td>40.65</td>\n",
       "      <td>360</td>\n",
       "      <td>390000.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Single Detached</td>\n",
       "      <td>12</td>\n",
       "      <td>L9T</td>\n",
       "      <td>70 and over</td>\n",
       "      <td>Male</td>\n",
       "      <td>78000</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>710</td>\n",
       "      <td>FUNDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CAX_Train_3</td>\n",
       "      <td>3</td>\n",
       "      <td>531000</td>\n",
       "      <td>2152</td>\n",
       "      <td>30.97</td>\n",
       "      <td>80.00</td>\n",
       "      <td>35.41</td>\n",
       "      <td>360</td>\n",
       "      <td>424800.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Single Detached</td>\n",
       "      <td>6</td>\n",
       "      <td>M1N</td>\n",
       "      <td>35-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>87000</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>709</td>\n",
       "      <td>FUNDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CAX_Train_4</td>\n",
       "      <td>4</td>\n",
       "      <td>1200000</td>\n",
       "      <td>5410</td>\n",
       "      <td>19.04</td>\n",
       "      <td>75.00</td>\n",
       "      <td>34.14</td>\n",
       "      <td>360</td>\n",
       "      <td>960000.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Single Detached</td>\n",
       "      <td>12</td>\n",
       "      <td>M2M</td>\n",
       "      <td>45-49</td>\n",
       "      <td>Male</td>\n",
       "      <td>300000</td>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td>761</td>\n",
       "      <td>FUNDED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CAX_Train_5</td>\n",
       "      <td>5</td>\n",
       "      <td>350000</td>\n",
       "      <td>3342</td>\n",
       "      <td>29.59</td>\n",
       "      <td>80.00</td>\n",
       "      <td>34.85</td>\n",
       "      <td>360</td>\n",
       "      <td>592000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Single Detached</td>\n",
       "      <td>12</td>\n",
       "      <td>L7G</td>\n",
       "      <td>50-54</td>\n",
       "      <td>Male</td>\n",
       "      <td>147000</td>\n",
       "      <td>8</td>\n",
       "      <td>62</td>\n",
       "      <td>762</td>\n",
       "      <td>FUNDED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unique_ID  MORTGAGE NUMBER  PROPERTY VALUE  MORTGAGE PAYMENT    GDS  \\\n",
       "0  CAX_Train_1                1          900000              5429  61.98   \n",
       "1  CAX_Train_2                2          386000              2179  35.22   \n",
       "2  CAX_Train_3                3          531000              2152  30.97   \n",
       "3  CAX_Train_4                4         1200000              5410  19.04   \n",
       "4  CAX_Train_5                5          350000              3342  29.59   \n",
       "\n",
       "     LTV    TDS  AMORTIZATION  MORTGAGE AMOUNT  RATE  ...    PROPERTY TYPE  \\\n",
       "0  65.00  71.63           360        1040000.0   4.0  ...  Single Detached   \n",
       "1  74.29  40.65           360         390000.0   4.5  ...  Single Detached   \n",
       "2  80.00  35.41           360         424800.0   3.5  ...  Single Detached   \n",
       "3  75.00  34.14           360         960000.0   5.5  ...  Single Detached   \n",
       "4  80.00  34.85           360         592000.0   5.0  ...  Single Detached   \n",
       "\n",
       "  TERM  FSA    AGE RANGE  GENDER  INCOME INCOME TYPE  NAICS CODE  \\\n",
       "0   12  L4C     Under 25    Male  108000           8       44-45   \n",
       "1   12  L9T  70 and over    Male   78000           2          56   \n",
       "2    6  M1N        35-39  Female   87000           2          72   \n",
       "3   12  M2M        45-49    Male  300000           8          54   \n",
       "4   12  L7G        50-54    Male  147000           8          62   \n",
       "\n",
       "   CREDIT SCORE  RESULT  \n",
       "0           681  FUNDED  \n",
       "1           710  FUNDED  \n",
       "2           709  FUNDED  \n",
       "3           761  FUNDED  \n",
       "4           762  FUNDED  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FUNDED        36023\n",
       "NOT FUNDED     9619\n",
       "Name: RESULT, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.RESULT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARJUlEQVR4nO3df5BdZX3H8feHAP4YpaJZp5IQQzWMZigFXIHWUanQTmDGxKoV6DAoOqZa0Vp/zOBo0cZxasXW8Qe1TSsoTAsiVo0aZSyCpS0oYYRIQqMRUTKoiQooImDw2z/uWbls7iZLzNkl+7xfM3dyzznPPvd7M3f3c89zznlOqgpJUrv2me0CJEmzyyCQpMYZBJLUOINAkhpnEEhS4/ad7QIeqvnz59fixYtnuwxJ2qtcd911P6qqsVHb9rogWLx4MevWrZvtMiRpr5Lku1Ntc2hIkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNa63IEhyXpKtSW6cYnuSfCDJ5iTrkxzVVy2SpKn1uUfwUWDZTrafCCzpHiuBD/dYiyRpCr0FQVX9F/CTnTRZAVxQA9cAj0vypL7qkSSNNptXFi8Abh1a3tKt+/7khklWMthrYNGiRb/xCz/jzRf8xn1o7rnunNNnuwS+t+p3Z7sEPQwtOvsbvfY/mweLM2LdyNulVdXqqhqvqvGxsZFTZUiSdtNsBsEW4OCh5YXAbbNUiyQ1azaDYA1wenf20LHAnVW1w7CQJKlfvR0jSHIRcBwwP8kW4O3AfgBV9U/AWuAkYDNwN3BGX7VIkqbWWxBU1am72F7Aa/p6fUnS9HhlsSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxvQZBkmVJNiXZnOSsEdsXJbkiydeTrE9yUp/1SJJ21FsQJJkHnAucCCwFTk2ydFKztwGXVNWRwCnAP/ZVjyRptD73CI4GNlfVzVV1H3AxsGJSmwIO6J7/FnBbj/VIkkboMwgWALcOLW/p1g17B3Baki3AWuC1ozpKsjLJuiTrtm3b1ketktSsPoMgI9bVpOVTgY9W1ULgJODCJDvUVFWrq2q8qsbHxsZ6KFWS2tVnEGwBDh5aXsiOQz+vAC4BqKqrgUcC83usSZI0SZ9BcC2wJMkhSfZncDB4zaQ23wOOB0jydAZB4NiPJM2g3oKgqrYDZwKXATcxODtoQ5JVSZZ3zd4IvDLJDcBFwMuqavLwkSSpR/v22XlVrWVwEHh43dlDzzcCz+qzBknSznllsSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxvQZBkmVJNiXZnOSsKdq8JMnGJBuS/Huf9UiSdrRvXx0nmQecC/wRsAW4Nsmaqto41GYJ8BbgWVV1e5In9lWPJGm0PvcIjgY2V9XNVXUfcDGwYlKbVwLnVtXtAFW1tcd6JEkj9BkEC4Bbh5a3dOuGHQocmuR/klyTZFmP9UiSRuhtaAjIiHU14vWXAMcBC4GrkhxWVXc8qKNkJbASYNGiRXu+UklqWJ97BFuAg4eWFwK3jWjzmar6ZVV9B9jEIBgepKpWV9V4VY2PjY31VrAktajPILgWWJLkkCT7A6cAaya1+TTwhwBJ5jMYKrq5x5okSZP0FgRVtR04E7gMuAm4pKo2JFmVZHnX7DLgx0k2AlcAb66qH/dVkyRpR9M6RpDk8qo6flfrJquqtcDaSevOHnpewBu6hyRpFuw0CJI8Eng0MD/JgTxwAPgA4KCea5MkzYBd7RH8OfB6Bn/0r+OBIPgpg4vFJEl7uZ0GQVW9H3h/ktdW1QdnqCZJ0gya1jGCqvpgkj8AFg//TFVd0FNdkqQZMt2DxRcCTwGuB+7vVhdgEEjSXm66VxaPA0u7s3wkSXPIdK8juBH47T4LkSTNjunuEcwHNib5GnDvxMqqWj71j0iS9gbTDYJ39FmEJGn2TPesoa/0XYgkaXZM96yhn/HAFNL7A/sBP6+qA/oqTJI0M6a7R/DY4eUkL2BwBzJJ0l5ut2YfrapPA8/bw7VIkmbBdIeGXji0uA+D6wq8pkCS5oDpnjX0/KHn24Fb2PFG9JKkvdB0jxGc0XchkqTZMa1jBEkWJvlUkq1Jfpjkk0kW9l2cJKl/0z1YfD6D+w0fBCwAPtutkyTt5aYbBGNVdX5Vbe8eHwXGeqxLkjRDphsEP0pyWpJ53eM0wJvMS9IcMN0geDnwEuAHwPeBFwMeQJakOWC6p4++E3hpVd0OkOTxwHsZBIQkaS823T2CwydCAKCqfgIc2U9JkqSZNN0g2CfJgRML3R7BdPcmJEkPY9P9Y/73wP8muZTB1BIvAd7VW1WSpBkz3SuLL0iyjsFEcwFeWFUbe61MkjQjpj280/3h94+/JM0xuzUNtSRp7jAIJKlxBoEkNc4gkKTGGQSS1DiDQJIa12sQJFmWZFOSzUnO2km7FyepJON91iNJ2lFvQZBkHnAucCKwFDg1ydIR7R4LvA74al+1SJKm1ucewdHA5qq6uaruAy5m9A3v3wm8B7inx1okSVPoMwgWALcOLW/p1v1akiOBg6vqczvrKMnKJOuSrNu2bduer1SSGtZnEGTEuvr1xmQf4H3AG3fVUVWtrqrxqhofG/MOmZK0J/UZBFuAg4eWFwK3DS0/FjgMuDLJLcCxwBoPGEvSzOozCK4FliQ5JMn+wCnAmomNVXVnVc2vqsVVtRi4BlheVet6rEmSNElvQVBV24EzgcuAm4BLqmpDklVJlvf1upKkh6bXu4xV1Vpg7aR1Z0/R9rg+a5EkjeaVxZLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTG9RoESZYl2ZRkc5KzRmx/Q5KNSdYnuTzJk/usR5K0o96CIMk84FzgRGApcGqSpZOafR0Yr6rDgUuB9/RVjyRptD73CI4GNlfVzVV1H3AxsGK4QVVdUVV3d4vXAAt7rEeSNEKfQbAAuHVoeUu3biqvAL4wakOSlUnWJVm3bdu2PViiJKnPIMiIdTWyYXIaMA6cM2p7Va2uqvGqGh8bG9uDJUqS9u2x7y3AwUPLC4HbJjdKcgLwVuC5VXVvj/VIkkboc4/gWmBJkkOS7A+cAqwZbpDkSOCfgeVVtbXHWiRJU+gtCKpqO3AmcBlwE3BJVW1IsirJ8q7ZOcBjgE8kuT7Jmim6kyT1pM+hIapqLbB20rqzh56f0OfrS5J2zSuLJalxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcb0GQZJlSTYl2ZzkrBHbH5Hk4932ryZZ3Gc9kqQd9RYESeYB5wInAkuBU5MsndTsFcDtVfVU4H3A3/VVjyRptD73CI4GNlfVzVV1H3AxsGJSmxXAx7rnlwLHJ0mPNUmSJtm3x74XALcOLW8BjpmqTVVtT3In8ATgR8ONkqwEVnaLdyXZ1EvFbZrPpP/vVuW9L53tEvRgfjYnvH2PfD9+8lQb+gyCUZXXbrShqlYDq/dEUXqwJOuqany265Am87M5c/ocGtoCHDy0vBC4bao2SfYFfgv4SY81SZIm6TMIrgWWJDkkyf7AKcCaSW3WABP74y8GvlxVO+wRSJL609vQUDfmfyZwGTAPOK+qNiRZBayrqjXAR4ALk2xmsCdwSl/1aEoOuenhys/mDIlfwCWpbV5ZLEmNMwgkqXEGwRyU5C+T3JhkQ5LXD61/bTflx4Yk7+nWPSHJFUnuSvKhSf2cnGT9cHvpoUjyyCRfS3JD9zn6m259krwryTeT3JTkdUPrP9BNO7M+yVHd+iOSXN31sT7JyUOv8ZGu//VJLk3ymNl5t3uvPq8j0CxIchjwSgZXdt8HfDHJ5xmcvrsCOLyq7k3yxO5H7gH+Gjise0z08wTgHOAZVbUtyceSHF9Vl8/g29He717geVV1V5L9gP9O8gXg6QxOHX9aVf1q6PN4IrCkexwDfLj7927g9Kr6VpKDgOuSXFZVdwB/VVU/BUjyD8CZwLtn8D3u9QyCuefpwDVVdTdAkq8AfwKMA++uqnsBqmpr9+/PGfxyPnVSP78DfLOqtnXL/wm8CDAING3d6eB3dYv7dY8CXg38WVX9qmu3tWuzArig+7lrkjwuyZOq6ptDfd6WZCswBtwxFAIBHsWIi1K1cw4NzT03As/phnweDZzE4JvXocCzu1lev5LkmbvoZzPwtCSLu4v9XsCDLxCUpiXJvCTXA1uBL1XVV4GnACcnWZfkC0mWdM1HTU2zYFJ/RwP7A98eWnc+8APgacAHe3szc5RBMMdU1U0MZnH9EvBF4AZgO4O9vwOBY4E3A5fsbIK/qrqdwbe2jwNXAbd0/UgPSVXdX1VHMBiePLobvnwEcE83hcS/AOd1zXc67UySJwEXAmdM7E10r3EGcBBwE3DyDj1opwyCOaiqPlJVR1XVcxhcqPctBt+s/qMGvgb8isGkXjvr57NVdUxV/T6wqetH2i3deP6VwDIGn8dPdps+BRzePZ9yapokBwCfB95WVdeM6P9+Bl9cXtRD+XOaQTAHTRx4S7IIeCFwEfBp4Hnd+kMZ7FrvdGbHoX4OBP4C+Nf+qtZclGQsyeO6548CTgD+j6HPI/BcYOIYwBrg9O7soWOBO6vq+900NZ9icPzgE0P9Z+L4VreH+/yufz0EXlk8ByW5isF03r8E3lBVl3e/SOcBRzA4m+hNVfXlrv0twAEMwuEO4I+ramOSi4Df67pdVVUXz+w70d4uyeEM7jkyj8EXz0uqalUXDv8GLGJwMPlVVXVD98f8Qwz2Gu5mMAS0LslpwPnAhqHuXwasZzB0eQCDYaUbgFdPHEDW9BgEktQ4h4YkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEKh5Se5Pcn03Y+tnh857X5zkF922icfp3baXJ/lGN+PljUlWdOuvTDI+1PfiJDd2z49L8rlJr72m63dzkjuHXueYmfsfUOucdE6CX3RTIJDkY8BrgHd12749sW1CkoXAW4GjqurObtrjsd154apa3vV5AnBmVb1gN9+DtNsMAunBruaB6Q6m8kTgZ3SzalbVXTwww6a013FoSOokmQccz2CagwlPmTQ09GwGV6/+EPhOkvOTPH826pX2FPcIJHhUN03yYuA6BjO3TthhaAggyTLgmQyC431JnlFV72D0XPhevq+HNfcIpAeOETyZwXxLr9nVD0zM4lpVfwucwgMzXv6YwXTfEx7PLib3k2abQSB1qupO4HXAm7rbKo6U5KCJe+l2jgC+2z2/Ejht6F4PLwWu6KFcaY9xaEgaUlVfT3IDg2/5V9EdIxhqch7wGeC93b1z7wG2Aa/qtq9mcJesG5IUsA54y9DPH59ky9Dyn1bV1f28G2l6nH1Ukhrn0JAkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY37f/m9XrHDau/ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x=train.RESULT.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45642 entries, 0 to 45641\n",
      "Data columns (total 22 columns):\n",
      "Unique_ID            45642 non-null object\n",
      "MORTGAGE NUMBER      45642 non-null int64\n",
      "PROPERTY VALUE       45642 non-null int64\n",
      "MORTGAGE PAYMENT     45642 non-null int64\n",
      "GDS                  45642 non-null float64\n",
      "LTV                  45642 non-null float64\n",
      "TDS                  45642 non-null float64\n",
      "AMORTIZATION         45642 non-null int64\n",
      "MORTGAGE AMOUNT      45642 non-null float64\n",
      "RATE                 45642 non-null float64\n",
      "MORTGAGE PURPOSE     45642 non-null object\n",
      "PAYMENT FREQUENCY    45642 non-null object\n",
      "PROPERTY TYPE        45642 non-null object\n",
      "TERM                 45642 non-null int64\n",
      "FSA                  45642 non-null object\n",
      "AGE RANGE            45642 non-null object\n",
      "GENDER               45642 non-null object\n",
      "INCOME               45642 non-null int64\n",
      "INCOME TYPE          45642 non-null int64\n",
      "NAICS CODE           45642 non-null object\n",
      "CREDIT SCORE         45642 non-null int64\n",
      "RESULT               45642 non-null object\n",
      "dtypes: float64(5), int64(8), object(9)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique_ID            0.0\n",
       "MORTGAGE NUMBER      0.0\n",
       "PROPERTY VALUE       0.0\n",
       "MORTGAGE PAYMENT     0.0\n",
       "GDS                  0.0\n",
       "LTV                  0.0\n",
       "TDS                  0.0\n",
       "AMORTIZATION         0.0\n",
       "MORTGAGE AMOUNT      0.0\n",
       "RATE                 0.0\n",
       "MORTGAGE PURPOSE     0.0\n",
       "PAYMENT FREQUENCY    0.0\n",
       "PROPERTY TYPE        0.0\n",
       "TERM                 0.0\n",
       "FSA                  0.0\n",
       "AGE RANGE            0.0\n",
       "GENDER               0.0\n",
       "INCOME               0.0\n",
       "INCOME TYPE          0.0\n",
       "NAICS CODE           0.0\n",
       "CREDIT SCORE         0.0\n",
       "RESULT               0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_missing = train.isna()\n",
    "train_num_missing = train_missing.sum()\n",
    "train_num_missing / len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('O'), dtype('int64'), dtype('float64')], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_types = pd.DataFrame(train.dtypes, columns=['type'])\n",
    "data_types['Feature'] = data_types.index\n",
    "data_types.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Unique_ID', 'RESULT', 'FSA']\n",
    "df_funded = train[train.RESULT == 'FUNDED']\n",
    "df_not_funded = train[train.RESULT == 'NOT FUNDED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_object(funded, not_funded, col):\n",
    "    fig= plt.figure(figsize=(12,5))\n",
    "    legend = ['Funded', 'Not Funded']\n",
    "    plt.hist([funded, not_funded], color=['red', 'blue'])\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend(legend)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_hist(funded, not_funded, col):\n",
    "    legend = ['Funded', 'Not Funded']\n",
    "    plt.hist([funded, not_funded], color=['red', 'blue'])\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend(legend)\n",
    "    plt.xticks(range(0, 7))\n",
    "    plt.yticks(range(1, 20))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,row in data_types.iterrows():\n",
    "#    if row.Feature not in cols_to_drop:\n",
    "#        col = row.Feature\n",
    "#        funded = df_funded[col]\n",
    "#        not_funded = df_not_funded[col]\n",
    "#        if row.type == \"object\":\n",
    "#            plot_hist_object(funded, not_funded, col)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WOE and IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas.core.algorithms as algos\n",
    "from pandas import Series\n",
    "import scipy.stats.stats as stats\n",
    "import re\n",
    "import traceback\n",
    "import string\n",
    "\n",
    "max_bin = 20\n",
    "force_bin = 3\n",
    "\n",
    "# define a binning function\n",
    "def mono_bin(Y, X, n = max_bin):\n",
    "    \n",
    "    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
    "    justmiss = df1[['X','Y']][df1.X.isnull()]\n",
    "    notmiss = df1[['X','Y']][df1.X.notnull()]\n",
    "    r = 0\n",
    "    while np.abs(r) < 1:\n",
    "        try:\n",
    "            d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.qcut(notmiss.X, n)})\n",
    "            d2 = d1.groupby('Bucket', as_index=True)\n",
    "            r, p = stats.spearmanr(d2.mean().X, d2.mean().Y)\n",
    "            n = n - 1 \n",
    "        except Exception as e:\n",
    "            n = n - 1\n",
    "\n",
    "    if len(d2) == 1:\n",
    "        n = force_bin         \n",
    "        bins = algos.quantile(notmiss.X, np.linspace(0, 1, n))\n",
    "        if len(np.unique(bins)) == 2:\n",
    "            bins = np.insert(bins, 0, 1)\n",
    "            bins[1] = bins[1]-(bins[1]/2)\n",
    "        d1 = pd.DataFrame({\"X\": notmiss.X, \"Y\": notmiss.Y, \"Bucket\": pd.cut(notmiss.X, np.unique(bins),include_lowest=True)}) \n",
    "        d2 = d1.groupby('Bucket', as_index=True)\n",
    "    \n",
    "    d3 = pd.DataFrame({},index=[])\n",
    "    d3[\"MIN_VALUE\"] = d2.min().X\n",
    "    d3[\"MAX_VALUE\"] = d2.max().X\n",
    "    d3[\"COUNT\"] = d2.count().Y\n",
    "    d3[\"EVENT\"] = d2.sum().Y\n",
    "    d3[\"NONEVENT\"] = d2.count().Y - d2.sum().Y\n",
    "    d3=d3.reset_index(drop=True)\n",
    "    \n",
    "    if len(justmiss.index) > 0:\n",
    "        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
    "        d4[\"MAX_VALUE\"] = np.nan\n",
    "        d4[\"COUNT\"] = justmiss.count().Y\n",
    "        d4[\"EVENT\"] = justmiss.sum().Y\n",
    "        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
    "        d3 = d3.append(d4,ignore_index=True)\n",
    "    \n",
    "    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
    "    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
    "    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
    "    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
    "    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"VAR_NAME\"] = \"VAR\"\n",
    "    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]       \n",
    "    d3 = d3.replace([np.inf, -np.inf], 0)\n",
    "    d3.IV = d3.IV.sum()\n",
    "    \n",
    "    return(d3)\n",
    "\n",
    "def char_bin(Y, X):\n",
    "        \n",
    "    df1 = pd.DataFrame({\"X\": X, \"Y\": Y})\n",
    "    justmiss = df1[['X','Y']][df1.X.isnull()]\n",
    "    notmiss = df1[['X','Y']][df1.X.notnull()]    \n",
    "    df2 = notmiss.groupby('X',as_index=True)\n",
    "    \n",
    "    d3 = pd.DataFrame({},index=[])\n",
    "    d3[\"COUNT\"] = df2.count().Y\n",
    "    d3[\"MIN_VALUE\"] = df2.sum().Y.index\n",
    "    d3[\"MAX_VALUE\"] = d3[\"MIN_VALUE\"]\n",
    "    d3[\"EVENT\"] = df2.sum().Y\n",
    "    d3[\"NONEVENT\"] = df2.count().Y - df2.sum().Y\n",
    "    \n",
    "    if len(justmiss.index) > 0:\n",
    "        d4 = pd.DataFrame({'MIN_VALUE':np.nan},index=[0])\n",
    "        d4[\"MAX_VALUE\"] = np.nan\n",
    "        d4[\"COUNT\"] = justmiss.count().Y\n",
    "        d4[\"EVENT\"] = justmiss.sum().Y\n",
    "        d4[\"NONEVENT\"] = justmiss.count().Y - justmiss.sum().Y\n",
    "        d3 = d3.append(d4,ignore_index=True)\n",
    "    \n",
    "    d3[\"EVENT_RATE\"] = d3.EVENT/d3.COUNT\n",
    "    d3[\"NON_EVENT_RATE\"] = d3.NONEVENT/d3.COUNT\n",
    "    d3[\"DIST_EVENT\"] = d3.EVENT/d3.sum().EVENT\n",
    "    d3[\"DIST_NON_EVENT\"] = d3.NONEVENT/d3.sum().NONEVENT\n",
    "    d3[\"WOE\"] = np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"IV\"] = (d3.DIST_EVENT-d3.DIST_NON_EVENT)*np.log(d3.DIST_EVENT/d3.DIST_NON_EVENT)\n",
    "    d3[\"VAR_NAME\"] = \"VAR\"\n",
    "    d3 = d3[['VAR_NAME','MIN_VALUE', 'MAX_VALUE', 'COUNT', 'EVENT', 'EVENT_RATE', 'NONEVENT', 'NON_EVENT_RATE', 'DIST_EVENT','DIST_NON_EVENT','WOE', 'IV']]      \n",
    "    d3 = d3.replace([np.inf, -np.inf], 0)\n",
    "    d3.IV = d3.IV.sum()\n",
    "    d3 = d3.reset_index(drop=True)\n",
    "    \n",
    "    return(d3)\n",
    "\n",
    "def data_vars(df1, target):\n",
    "    \n",
    "    stack = traceback.extract_stack()\n",
    "    filename, lineno, function_name, code = stack[-2]\n",
    "    vars_name = re.compile(r'\\((.*?)\\).*$').search(code).groups()[0]\n",
    "    final = (re.findall(r\"[\\w']+\", vars_name))[-1]\n",
    "    \n",
    "    x = df1.dtypes.index\n",
    "    count = -1\n",
    "    \n",
    "    for i in x:\n",
    "        if i.upper() not in (final.upper()):\n",
    "            if np.issubdtype(df1[i], np.number) and len(Series.unique(df1[i])) > 2:\n",
    "                conv = mono_bin(target, df1[i])\n",
    "                conv[\"VAR_NAME\"] = i\n",
    "                count = count + 1\n",
    "            else:\n",
    "                conv = char_bin(target, df1[i])\n",
    "                conv[\"VAR_NAME\"] = i            \n",
    "                count = count + 1\n",
    "                \n",
    "            if count == 0:\n",
    "                iv_df = conv\n",
    "            else:\n",
    "                iv_df = iv_df.append(conv,ignore_index=True)\n",
    "    \n",
    "    iv = pd.DataFrame({'IV':iv_df.groupby('VAR_NAME').IV.max()})\n",
    "    iv = iv.reset_index()\n",
    "    return(iv_df,iv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train\n",
    "df['target'] = df['RESULT'].apply(lambda x : 1 if x == 'FUNDED' else 0)  # Convert to numeric\n",
    "df = df.drop(['Unique_ID', 'RESULT', 'MORTGAGE NUMBER'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = train['target']\n",
    "X = df.drop(['target'],axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.10, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_iv, IV = data_vars(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VAR_NAME</th>\n",
       "      <th>IV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>INCOME TYPE</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CREDIT SCORE</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>GDS</td>\n",
       "      <td>0.000486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AMORTIZATION</td>\n",
       "      <td>0.000701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>TDS</td>\n",
       "      <td>0.002831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>GENDER</td>\n",
       "      <td>0.003137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>INCOME</td>\n",
       "      <td>0.003495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>AGE RANGE</td>\n",
       "      <td>0.003552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>PAYMENT FREQUENCY</td>\n",
       "      <td>0.006673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>TERM</td>\n",
       "      <td>0.008699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>PROPERTY TYPE</td>\n",
       "      <td>0.016790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>NAICS CODE</td>\n",
       "      <td>0.024748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>MORTGAGE AMOUNT</td>\n",
       "      <td>0.035554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>PROPERTY VALUE</td>\n",
       "      <td>0.040395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>RATE</td>\n",
       "      <td>0.042052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>LTV</td>\n",
       "      <td>0.046775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>MORTGAGE PURPOSE</td>\n",
       "      <td>0.059908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>MORTGAGE PAYMENT</td>\n",
       "      <td>0.073015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FSA</td>\n",
       "      <td>0.184769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             VAR_NAME        IV\n",
       "7         INCOME TYPE  0.000004\n",
       "2        CREDIT SCORE  0.000322\n",
       "4                 GDS  0.000486\n",
       "1        AMORTIZATION  0.000701\n",
       "17                TDS  0.002831\n",
       "5              GENDER  0.003137\n",
       "6              INCOME  0.003495\n",
       "0           AGE RANGE  0.003552\n",
       "13  PAYMENT FREQUENCY  0.006673\n",
       "18               TERM  0.008699\n",
       "14      PROPERTY TYPE  0.016790\n",
       "12         NAICS CODE  0.024748\n",
       "9     MORTGAGE AMOUNT  0.035554\n",
       "15     PROPERTY VALUE  0.040395\n",
       "16               RATE  0.042052\n",
       "8                 LTV  0.046775\n",
       "11   MORTGAGE PURPOSE  0.059908\n",
       "10   MORTGAGE PAYMENT  0.073015\n",
       "3                 FSA  0.184769"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IV.sort_values('IV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV.to_csv('IV.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply WOE values to your dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_vars_list = x_train.columns\n",
    "transform_prefix = 'new_' # leave this value blank if you need replace the original column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PROPERTY VALUE', 'MORTGAGE PAYMENT', 'GDS', 'LTV', 'TDS',\n",
       "       'AMORTIZATION', 'MORTGAGE AMOUNT', 'RATE', 'MORTGAGE PURPOSE',\n",
       "       'PAYMENT FREQUENCY', 'PROPERTY TYPE', 'TERM', 'FSA', 'AGE RANGE',\n",
       "       'GENDER', 'INCOME', 'INCOME TYPE', 'NAICS CODE', 'CREDIT SCORE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_vars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_WOE(df, transform_vars_list, final_iv):\n",
    "    \n",
    "    for var in transform_vars_list:\n",
    "        small_df = final_iv[final_iv['VAR_NAME'] == var]\n",
    "        transform_dict = dict(zip(small_df.MAX_VALUE,small_df.WOE))\n",
    "        replace_cmd = ''\n",
    "        replace_cmd1 = ''\n",
    "        for i in sorted(transform_dict.items()):\n",
    "            replace_cmd = replace_cmd + str(i[1]) + str(' if x <= ') + str(i[0]) + ' else '\n",
    "            replace_cmd1 = replace_cmd1 + str(i[1]) + str(' if x == \"') + str(i[0]) + '\" else '\n",
    "        replace_cmd = replace_cmd + '0'\n",
    "        replace_cmd1 = replace_cmd1 + '0'\n",
    "        if replace_cmd != '0':\n",
    "            try:\n",
    "                df[transform_prefix + var] = df[var].apply(lambda x: eval(replace_cmd))\n",
    "            except:\n",
    "                df[transform_prefix + var] = df[var].apply(lambda x: eval(replace_cmd1))\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train_new = apply_WOE(x_train, transform_vars_list, final_iv)\n",
    "#x_test_new = apply_WOE(x_test, transform_vars_list, final_iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in transform_vars_list:\n",
    "    small_df = final_iv[final_iv['VAR_NAME'] == var]\n",
    "    transform_dict = dict(zip(small_df.MAX_VALUE,small_df.WOE))\n",
    "    replace_cmd = ''\n",
    "    replace_cmd1 = ''\n",
    "    for i in sorted(transform_dict.items()):\n",
    "        replace_cmd = replace_cmd + str(i[1]) + str(' if x <= ') + str(i[0]) + ' else '\n",
    "        replace_cmd1 = replace_cmd1 + str(i[1]) + str(' if x == \"') + str(i[0]) + '\" else '\n",
    "    replace_cmd = replace_cmd + '0'\n",
    "    replace_cmd1 = replace_cmd1 + '0'\n",
    "    if replace_cmd != '0':\n",
    "        try:\n",
    "            x_train[transform_prefix + var] = x_train[var].apply(lambda x: eval(replace_cmd))\n",
    "        except:\n",
    "            x_train[transform_prefix + var] = x_train[var].apply(lambda x: eval(replace_cmd1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in transform_vars_list:\n",
    "    small_df = final_iv[final_iv['VAR_NAME'] == var]\n",
    "    transform_dict = dict(zip(small_df.MAX_VALUE,small_df.WOE))\n",
    "    replace_cmd = ''\n",
    "    replace_cmd1 = ''\n",
    "    for i in sorted(transform_dict.items()):\n",
    "        replace_cmd = replace_cmd + str(i[1]) + str(' if x <= ') + str(i[0]) + ' else '\n",
    "        replace_cmd1 = replace_cmd1 + str(i[1]) + str(' if x == \"') + str(i[0]) + '\" else '\n",
    "    replace_cmd = replace_cmd + '0'\n",
    "    replace_cmd1 = replace_cmd1 + '0'\n",
    "    if replace_cmd != '0':\n",
    "        try:\n",
    "            x_test[transform_prefix + var] = x_test[var].apply(lambda x: eval(replace_cmd))\n",
    "        except:\n",
    "            x_test[transform_prefix + var] = x_test[var].apply(lambda x: eval(replace_cmd1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import  metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, ytrain, dtest, ytest, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=ytrain.values)\n",
    "        xgtest = xgb.DMatrix(dtest[predictors].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], ytrain, eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(ytrain.values, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(ytrain, dtrain_predprob))\n",
    "    \n",
    "    #Predict on testing data:\n",
    "    predprob = alg.predict_proba(dtest[predictors])[:,1]\n",
    "    print('AUC Score (Test): %f' % metrics.roc_auc_score(ytest, predprob))\n",
    "                \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1- Find the number of estimators for a high learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[19:55:38] src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-c8a6cd5406ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         seed=27)\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodelfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-cbb4b9066a2c>\u001b[0m in \u001b[0;36mmodelfit\u001b[1;34m(alg, dtrain, ytrain, dtest, ytest, predictors, useTrainCV, cv_folds, early_stopping_rounds)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mxgtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n\u001b[1;32m----> 8\u001b[1;33m             metrics='auc', early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcvresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[0;32m    443\u001b[0m                            evaluation_result_list=None))\n\u001b[0;32m    444\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1109\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFiles\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \"\"\"\n\u001b[0;32m    175\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [19:55:38] src/learner.cc:723: Check failed: mparam_.num_feature != 0 (0 vs. 0) : 0 feature is supplied.  Are you using raw Booster interface?"
     ]
    }
   ],
   "source": [
    "predictors = [x for x in train.columns if \"new\" in x]\n",
    "\n",
    "xgb1 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "\n",
    "modelfit(xgb1, x_train, y_train, x_test, y_test, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test1 = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "                                        min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    "                       param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test2 = {\n",
    "    'max_depth':[4,5,6],\n",
    "    'min_child_weight':[4,5,6]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    "                                        min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test2b = {\n",
    "    'min_child_weight':[6,8,10,12]\n",
    "}\n",
    "gsearch2b = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=4,\n",
    "                                        min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test2b, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2b.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch2b.grid_scores_, gsearch2b.best_params_, gsearch2b.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test3 = {\n",
    "    'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=4,\n",
    "                                        min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb2 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=4,\n",
    "        min_child_weight=6,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "modelfit(xgb2, x_train, y_train, x_test, y_test, predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test4 = {\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=4,\n",
    "                                        min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tune subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test5 = {\n",
    "    'subsample':[i/100.0 for i in range(75,90,5)],\n",
    "    'colsample_bytree':[i/100.0 for i in range(75,90,5)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=4,\n",
    "                                        min_child_weight=6, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch5.grid_scores_, gsearch5.best_params_, gsearch5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test6 = {\n",
    "    'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=4,\n",
    "                                        min_child_weight=6, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid seach on subsample and max_features\n",
    "#Choose all predictors except target & IDcols\n",
    "param_test7 = {\n",
    "    'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=177, max_depth=4,\n",
    "                                        min_child_weight=6, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "                                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "                       param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch7.fit(train[predictors],train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch7.grid_scores_, gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb3 = XGBClassifier(\n",
    "        learning_rate =0.1,\n",
    "        n_estimators=1000,\n",
    "        max_depth=4,\n",
    "        min_child_weight=6,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.005,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "modelfit(xgb3, x_train, y_train, x_test, y_test, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb4 = XGBClassifier(\n",
    "        learning_rate =0.01,\n",
    "        n_estimators=5000,\n",
    "        max_depth=4,\n",
    "        min_child_weight=6,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.005,\n",
    "        objective= 'binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=27)\n",
    "modelfit(xgb4, x_train, y_train, x_test, y_test, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
