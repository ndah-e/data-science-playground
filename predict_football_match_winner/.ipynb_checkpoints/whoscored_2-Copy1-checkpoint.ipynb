{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "# use feature importance for feature selection\n",
    "from numpy import loadtxt\n",
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# hidden neuron selection\n",
    "# one could get decent performance by setting the hidden layer configuration using just two rules: \n",
    "#(i) number of hidden layers equals one; and \n",
    "#(ii) the number of neurons in that layer is the mean of the neurons in the input and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/FootballEurope.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "#df.columns\n",
    "df.division.unique()\n",
    "#['EPL', 'Bundesliga', 'Ligue_1', 'La_Liga', 'Serie_A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df.homeGoalFT - df.awayGoalFT > 0, 'FTR'] = 'H' \n",
    "#df.loc[df.homeGoalFT - df.awayGoalFT == 0, 'FTR'] = 'D' \n",
    "#df.loc[df.homeGoalFT - df.awayGoalFT < 0, 'FTR'] = 'A'\n",
    "\n",
    "df.loc[df.homeGoalFT - df.awayGoalFT > 0, 'FTR'] = 0\n",
    "df.loc[df.homeGoalFT - df.awayGoalFT == 0, 'FTR'] = 1 \n",
    "df.loc[df.homeGoalFT - df.awayGoalFT < 0, 'FTR'] = 2\n",
    "\n",
    "df['FTG'] = df.homeGoalFT + df.awayGoalFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = ['homeGoalHT','awayGoalHT','homeGoalFT','awayGoalFT','FTR','FTG']\n",
    "numeric_cols = df.select_dtypes([np.number]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['id','homeTeamLineUp', 'awayTeamLineUp', 'homeFormation', 'awayFormation','awayManagerName','homeManagerName', \n",
    "                'venueName','date', 'division', 'FTR', 'FTG','awayGoalHT', 'homeGoalHT','homeGoalFT', 'awayGoalFT', \n",
    "                'division', 'homeTeam', 'awayTeam', 'refereeName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "def kruskal_walllis_asso(df,variables):\n",
    "    tmp_H = df[df.FTR == 'H']\n",
    "    tmp_D = df[df.FTR == 'D']\n",
    "    tmp_A = df[df.FTR == 'A']\n",
    "\n",
    "    pvalues = []\n",
    "\n",
    "    for var in variables:\n",
    "        stat, p = kruskal(tmp_H[var], tmp_D[var], tmp_A[var])\n",
    "        print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "        pvalues.append(p)\n",
    "        alpha = 0.05\n",
    "        if p > alpha:\n",
    "            print('No statistically significant difference between groups for ' + var)\n",
    "\n",
    "        print()\n",
    "        \n",
    "        return pvalues\n",
    "\n",
    "#feature_pvalues = pd.DataFrame({'feature':variables,'pvalue':pvalues}).sort_values(by='pvalue')\n",
    "\n",
    "#f, ax = plt.subplots(figsize=(12, 12))\n",
    "#sns.barplot(x=\"pvalue\", y=\"feature\", data=feature_pvalues)\n",
    "#plt.title('Features p values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.stats.stats import pearsonr \n",
    "#for var in variables:\n",
    "#    print(\"Correlation with \" + var)\n",
    "#    print(pearsonr(df[\"FTG\"],df[var])[0])\n",
    "#    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HT_cols = [col for col in df.columns if col[-2:] == 'HT']\n",
    "\n",
    "data = df\n",
    "#['EPL', 'Bundesliga', 'Ligue_1', 'La_Liga', 'Serie_A']\n",
    "#data = df[df.division == 'Ligue_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HT_cols = [col for col in df.columns if col[-2:] == 'HT']\n",
    "cols_to_drop = cols_to_drop + HT_cols\n",
    "\n",
    "variable = data.drop(cols_to_drop, axis=1).columns\n",
    "variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defence_vars_home = []\n",
    "defence_vars_away = []\n",
    "\n",
    "offence_vars_home = []\n",
    "offence_vars_away = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_letters\n",
    "\n",
    "#corr = df[variables]).corr()\n",
    "\n",
    "cols_to_drop = cols_to_drop + HT_cols\n",
    "corr = data.drop(cols_to_drop, axis=1)\n",
    "corr = corr.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "corr = data.drop(cols_to_drop, axis=1)\n",
    "def get_corrs(df):\n",
    "    col_correlations = df.corr()\n",
    "    col_correlations.loc[:, :] = np.tril(col_correlations, k=-1)\n",
    "    cor_pairs = col_correlations.stack()\n",
    "    \n",
    "    return cor_pairs.to_dict()\n",
    "\n",
    "my_corrs = get_corrs(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#HT_cols = [col for col in data.columns if col[-2:] == 'HT']\n",
    "#cols_to_drop = cols_to_drop + HT_cols\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "FTR = data.FTR\n",
    "x_train, x_test, y_train, y_test = train_test_split(data.drop(cols_to_drop, axis=1), FTR, train_size=0.90, \n",
    "                                                    test_size=0.1, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#x_train = x_train.drop(cols_to_drop, axis=1)\n",
    "#x_train = x_train.drop(cols_to_drop, axis=1)\n",
    "\n",
    "data = data.drop(HT_cols, axis = 1)\n",
    "\n",
    "#x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(oob_score=True, random_state=12)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred = rf.predict(x_test)\n",
    "#pred = rf.predict(x_test.drop(cols_to_drop, axis=1))\n",
    "\n",
    "print(pd.crosstab(y_test, pred))\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'feature':x_train.columns,\n",
    "                                   'importance':rf.feature_importances_}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importance.head(25))\n",
    "plt.title('Features Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on all training data\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = rf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "number_of_var = 2\n",
    "best_threshold = 0\n",
    "default_accuracy = accuracy\n",
    "thresholds = sort(rf.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    \n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(rf, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(x_train)\n",
    "    \n",
    "    # train model\n",
    "    selection_model = RandomForestClassifier(random_state=12)\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    \n",
    "    # eval model\n",
    "    select_X_test = selection.transform(x_test)\n",
    "    y_pred = selection_model.predict(select_X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n",
    "    \n",
    "    if default_accuracy < accuracy:\n",
    "        default_accuracy = accuracy\n",
    "        best_threshold = thresh\n",
    "        number_of_var = select_X_train.shape[1]\n",
    "\n",
    "best_threshold = round(best_threshold,4)\n",
    "print()\n",
    "print(\"Best results: \")\n",
    "print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (best_threshold, number_of_var, default_accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best subset of features\n",
    "print(best_threshold)\n",
    "best_feat = feature_importance[feature_importance.importance >= best_threshold]\n",
    "print(best_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=12)\n",
    "rf_model.fit(x_train[best_feat.feature], y_train)\n",
    "\n",
    "pred = rf_model.predict(x_test[best_feat.feature])\n",
    "print(pd.crosstab(y_test, pred))\n",
    "accuracy_score(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier(max_features='sqrt', oob_score = True) \n",
    "\n",
    "# Use a grid over parameters of interest\n",
    "param_grid = { \n",
    "           \"n_estimators\" : [18, 27, 36, 45, 54, 63, 79, 86, 95, 100, 120],\n",
    "           \"max_depth\" : [1, 5, 10, 15, 20, 25, 30, 35],\n",
    "           \"min_samples_leaf\" : [1, 2, 4, 6, 8, 10]}\n",
    "\n",
    "#CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 10)\n",
    "#CV_rfc.fit(x_train, y_train)\n",
    "#print(CV_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "\n",
    "gbm = xgb.XGBClassifier().fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_xgb_importances = pd.DataFrame({'feature':x_train.columns,\n",
    "                                   'Importance':gbm.feature_importances_}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.barplot(x=\"Importance\", y=\"feature\", data=feature_xgb_importances.head(30))\n",
    "plt.title('xgboost Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = gbm.predict(x_test)\n",
    "pred = np.asarray([np.argmax(line) for line in pred_prob])\n",
    "\n",
    "print(pd.crosstab(y_test, pred))\n",
    "accuracy_score(y_test, pred)\n",
    "#roc_auc_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fit model on all training data\n",
    "model = XGBClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions for test data and evaluate\n",
    "y_pred = model.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# Fit model using each importance as a threshold\n",
    "thresholds = sort(model.feature_importances_)\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(x_train)\n",
    "    # train model\n",
    "    selection_model = XGBClassifier()\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    # eval model\n",
    "    select_X_test = selection.transform(x_test)\n",
    "    y_pred = selection_model.predict(select_X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate prediction peroformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oob_error = []\n",
    "#for var in x_train.columns:\n",
    "#    df_tmp = x_train[var]\n",
    "#    df_tmp = df_tmp.values.reshape(-1, 1)\n",
    "#    rf.fit(df_tmp, y_train)\n",
    "#    oob_error.append(rf.oob_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_accuracy = pd.DataFrame({'feature':x_train.columns,\n",
    "#                                   'Accuracy':oob_error}).sort_values(by='Accuracy', ascending=False)\n",
    "#f, ax = plt.subplots(figsize=(12, 12))\n",
    "#sns.barplot(x=\"Accuracy\", y=\"feature\", data=feature_accuracy.head(30))\n",
    "#plt.title('Features Univariate accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best subset of features\n",
    "#best_feat = feature_accuracy[feature_accuracy.Accuracy >= 0.46]\n",
    "#best_feat = feature_accuracy.head(11)\n",
    "#print(len(best_feat))\n",
    "#print(best_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf.fit(x_train[best_feat.feature], y_train)\n",
    "#pred = rf.predict(x_train[best_feat.feature])\n",
    "#print(rf.oob_score_)\n",
    "#print(accuracy_score(y_train, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = rf.predict(x_test[best_feat.feature])\n",
    "#print(pd.crosstab(y_test, pred))\n",
    "#accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=5, verbosity=3)\n",
    "tpot.fit(x_train, y_train)\n",
    "print(tpot.score(x_test, y_test))\n",
    "tpot.export('tpot_pipeline.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
